

1) 整理内容

、、、
1. mysql主从备份延迟以及实际相关问题
	原理	
	异步
	主库对写的的操作写进binlog
	并产生一个线程 用户给从库I/O线程读取binlog日志
	从库请求主库的binlog日志 并将日志写到自己的relayl og日志中
	从库线程会读取relay log日志的内容解析成具体sql语句并执行
	主库是并发的 从库的单线程却不是
	
	可能延迟的原因
	主库负载过高 从库负载过高 网络延迟 机器性能低 mysql配置问题
	
	主从同步延迟的产生
	主库并发较高是 产生的数量超过从库一个sql线程的承受范围
	
	解决延迟的方法
	简单的减少slave同步延时的方案就是在架构上做优化，尽量让主库的DDL快速执行。	还有就是主库是写，对数据安全性较高，比如 sync_binlog=1，	innodb_flush_log_at_trx_commit = 1 之类的设置，而slave则不需要这么高的	数据安全，完全可以讲sync_binlog设置为0或者关闭binlog，innodb_flushlog也 	可以设置为0来提高sql的执行效率。另外就是使用比主库更好的硬件设备作为slave。
	

	
	

2.mysql查看连接进程
	show processlist;
	show status;

3.web网站访问慢排查都有哪些问题影响
	客户端
	（1）网络问题
	（2）dns解析问题
	访问其他网页没问题的话 那就是server端出现的问题
	（1）并发多了之后 服务器的出口带宽不够 或者夸运营商导致的带宽缩减
	（2）服务器负载过高 CPU内存消耗过高
	（3）查询数据库读写耗时太长 代码问题
	（4）数据库过于庞大没有进行优化 每次查询耗时长
	解决办法
	（1）出口带宽或者硬件的优化
	（2）mysql语句优化
	（3）数据库主从复制 读写分离
	（4）使用缓存机制把数据缓存到内存非关系型数据库
	（5）CDN
	（6）网站架构优化 服务器集群或者数据库集群

4.ftp的两种模式
	主动/被动

5.named启动过程
	dns服务器进程 当其启动时自动装载/etc/named.conf 文件定义的dns

6.dns解析过程
	nslookup/dig
	本地hosts - 浏览器缓存 - 系统缓存 -路由器缓存 - 运营商缓存 - 根域名服务器

7.一个目录大于100k的文件copy到另一个目录
	ll -h file awk | ‘{print $5}’
	find . -name ‘*.file’ -size +100k -exce cp -r {} \;
	
8.两个服务器拷贝文件的几种方法
	scp/ftp/wget

9.nginx rewrite各种参数理解以及相关内容
	nginx 可以挂在lua脚本

	last: url重写后，马上发起一个新请求 再次进入server 重新匹配location 超过十次就报500 地址栏不变
	break: url重写后，直接使用当前资源 不再执行location里剩下的语句 完成本次请求 地址栏不变
	redirect: 返回临时的重定向 地址栏显示重定向后的url 302 如果有爬虫不会更新url
	permanet: 返回永久重定向 地址看显示重定向后的url	 301 如果有爬虫会更新url
 	
	（1）proxy_set_header Host $host; 代理服务器携带者真是用户的host
	（2）proxy_set_header X-Real-IP $remote_addr; 携带者真实IP
	（3）proxy_set_header X-Forwarded $proxy_add_x_forwarded_for; 携带真实ip 
	（2）和（3）当服务器无法通过$proxy_add_x_forwarded_for获得ip时应该用$remote_addr;获取ip

	nginx负载均衡配置
	upstream name { server 1   weight=1;
				    server2   weight=2;
                           }
	***
	location / {  
       ****
	proxy_pass http://name;
      }

	nginx和apache区别

	nginx更轻量级占用资源内存少 异步非阻塞的 抗并发高 可以作为反向代理服务器 热升级

	apache同步多进程 nginx异步多个连接对应一个进程 apache 更稳定



	nginx功能:
	静态的web服务器
	反向代理
	负载均衡
	虚拟主机	
	请求转发


	nginx 中如果location 是 alias 必须 location 中的根目录 要和 alias 末级的文件夹一致


	location /admin {
          	alias   /home/data/admin;
          	auth_basic "User Authentication";
          	auth_basic_user_file "/etc/nginx/conf.d/nginxuser";
  

	nginx  中如果 location 是 root 必须 location 中的根目录 要包含在 root 目录中最后一级

	location /admin {
         	root    /home/data;
          	auth_basic "User Authentication";
          	auth_basic_user_file "/etc/nginx/conf.d/nginxuser";
  
          	}






10.ansible发送指令慢解决办法
	关掉 配置文件/etc/ansible/ansible.cfg 中验证秘钥的验证 host_key_checking = False
	网络问题
	关闭 gathering facts  总收集数据 只需要在 playbook 文件中加上“gather_facts: no”即可
	SSH pipelining 是一个加速 Ansible 执行速度的简单方法 默认关闭  之所以默认关闭是为了兼容不同的 sudo 配置 建议开启/etc/ansible/ansible.cfg 

11.linux 服务器优化方法有哪些

12.20台服务器并行 echo 123
	python  pexpect模块 / paramiko模块  远程连接主机模块

13.tcp/ip四层模型
	链路层-网络层-传输层-应用层

14.应用层常用协议
	http\https\DNS\SMTP\FTP

15.某台机器上80端口转发到8089端口上的方法
	本机端口转发:iptables -t nat -A PREROUTING -p tcp - -dport 80 -j REDIRECT - -to-ports 8080
	不同机器端口转发:
16.linux 防火墙相关设置

17.sed awk find grep常用方法
	find . -name ‘*.txt’ -type d -maxdepth 1 -mtime -1 -size +100k -exce cp -r {} /tmp/  找到当前大于100k的一级目录 最新一天修改过的 并copy到tmp目录下
	find . -type f -exec chmod -R 644 {} \;  当前目录下 所有文件授权644
	
	找到log日志文件删除30天以前的 ：find . -type f -name “*.log” -mtime +30 -exec rm -rf {} \;

	grep “([0-9]{1,3}\.){3}[0-9]{1,3}$” file 匹配ip地址

	awk -F ‘:’ ’{print $1，$NF} ‘ file | head -5 打印文件的第一列前五个	
	
	sed ‘$d’ file 删除 file文件的最后一行  
	sed -i ’s/原内容/替换内容/1’ file 替换字符串 s 参数是替换 1是替换第一个行以此类推 替换所有行用g

18.gitlab的安装配置以及备份还原

19.mysql、redis、php等编译安装
	musql初始设置 /etc/my.cnf 开启二进制日志 log-bin



20.http协议 tcp/ip协议
	tcp是一种面向连接的、可靠的传输层协议 tcp传输有三次握手 为应用层提供服务 点对点传输
	ip是网络互连的一种通信协议属于网络层 
	http 是一种超文本传输的应用层协议 基于tcp/ip协议（无状态协议没有记忆能力、无连接的每次只处理一个请求）有请求行、请求头和响构成



21.浏览器访问一个server的过程 一个完整的http请求过程
	浏览器输入域名 首先对域名进行解析 
	根据ip找到对应的服务器 发起tcp三次握手连接
	建立tcp连接之后发起http请求
	服务器响应http请求 返回给浏览器 浏览器解析呈献给用户
	


	

22.shell python





23.zabbix相关只是点zabbix_proxy
	
	zbbbix安装步骤:
		https://www.zabbix.com/cn/
		

	zabbix客户端安装 zabbix-agent zabbix-sender
	编辑/etc/zabbix/zabbix_agentd.conf的配置文件
	修改Server服务端的 IP地址
	修改主动模式下ServerActive服务端的IP地址
	修改Hostname 这个对应的是zabbix-server端web界面创建host时的主机名保持一致
	然后启动zabbix-agent.service

	手动添加:
		server端添加host configuration - Hosts - Create host

		添加完主机 - items代表要监控的项目 items - create item

		自定义监控内容 自定义key 编辑zabbix_agentd.conf下面一个配置文件内容监控内存使用：UserParameter=memory.used,/usr/bin/free -mh |/usr/bin/awk ‘/^Mem/{print $3}’ 
		重启agent服务

		server端命令行获取agent数据 zabbix_get 命令 先yum -y install zabbix_get 命令 再用zabbix_get -s agentip地址 -p agent端口号 -k “自定义文件里面的名称（memory.user）”
		检查没问题之后 server端web页面添加自定义的item即可（数据刷新有点延迟）
		
	添加监控的模板
		点开主机名 - 模板 - 添加 - 更新  —->自动添加模板的监控项

	自动发现策略:


		server端 configuration - create discover

		配置自动发现规则 名称 - IP地址范围 - 更新时间

		自动发现并添加主机清单 —->用到模板


	zabbix-proxy(分布式)

		和server端不是一个机器
		下载安装zabbix proxy
		yum install -y zabbix-proxy zabbix-proxy-mysql zabbix-agent
		创建zabbix_proxy数据库
		解压zabbix软件包 在解压完的目录里有个database导入两个sql文件
		mysql -uzabbix -p123456 zabbix_proxy < database/mysql/schema.sql
		mysql -uzabbix -p123456 zabbix_proxy < database/mysql/images.sql
				
		安装完zabbix_proxy 会在/usr/local/zabbix/etc/下产生一个zabbix_proxy.conf文件
		配置server端ip hostname 本机主机ip 以及数据库名的账号密码、发送提交数据给服务端的时间等设置

		设置好之后再服务端的web界面添加zabbix_proxy - create proxy - 添加代理服务器ip - 主动模式 - 添加
		添加好代理服务器之后 选择添加主机 如上面 手动添加过程 注意添加时选择是有代理服务器检测而不是server端监控
		添加好的主机也要选择监控项添加一个模板 如自动发现的模板
		客户端的/us/local/zabbix/etc/zabbix_agentd.conf 里面把指向server端的ip改成指向proxy端的ip地址才能获取到数据
		
		



24.gitlab-ci
	持续集成: 持续集成是一天多次将代码合并到主干 通过自动构建的方式验证每次提交 尽早发现问题
	持续集成的价值: 保持随时部署 简化发布流程 尽早发现问题

		






高可用性

jumpserver






















