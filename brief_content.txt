

1) 整理内容

、、、
1. mysql主从备份延迟以及实际相关问题
	原理	
	异步
	主库把写的的操作写进binlog
	并产生一个线程 用户给从库I/O线程读取binlog日志
	从库请求主库的binlog日志 并将日志写到自己的relayl og日志中
	从库线程会读取relay log日志的内容解析成具体sql语句并执行
	主库是并发的 从库的单线程却不是
	
	可能延迟的原因
	主库负载过高 从库负载过高 网络延迟 机器性能低 mysql配置问题
	
	主从同步延迟的产生
	主库并发较高是 产生的数量超过从库一个sql线程的承受范围
	
	解决延迟的方法
	简单的减少slave同步延时的方案就是在架构上做优化，尽量让主库的DDL快速执行。	还有就是主库是写，对数据安全性较高，比如 sync_binlog=1，	innodb_flush_log_at_trx_commit = 1 之类的设置，而slave则不需要这么高的	数据安全，完全可以讲sync_binlog设置为0或者关闭binlog，innodb_flushlog也 	可以设置为0来提高sql的执行效率。另外就是使用比主库更好的硬件设备作为slave。
	
	
	mysql备份
	   mysql rsync	
	   备份sql文件 mysqldump -uroot -p123456 -B 数据库名 表名> test.sql  还原 mysql -uroot -p123456 数据库名 < test.sql
           test文本备份 select * from student into outfile '/var/lib/mysql-files/tt.txt';  还原 load data infile '/var/lib/mysql-files/tt.txt' into table student;
	mysql设置客户端访问权限
	    grant all privileges on *.* to ‘root’@‘%’ identified by ‘123456’ with grant option;
	    flush privileges;

	mysql修改登录密码编辑/etc/my.cnf
		[mysqld]
		 skip-grant-tables —->跳过权限验证直接登录
		修改root密码 先刷新权限相关的表 flush privileges;
		set password for root@localhost = password(‘123456’);或者
		use mysql; update user set password=PASSWORD(‘123456’)WHERE user=’root’; 
		再刷新 flush privileges;
		最后在注释掉
		[mysqld]
		#skip-grant-tables
		重启mysql服务

	mysql主从复制读写分离分库分表
		主库从库有相同的数据库和表
		1.修改主服务器的同步日志my.cnf配置文件
		     添加
		     log-bin=master-a-bin #日志文件名称
		     binlog-format=ROW	#二进制日志格式 有row、statement、mixed三种类型
		     server-id=1 #要求各个服务器的这个id不一样
		     binlog-do-db=需要同步的数据库名称
		2.设置从服务器登陆主服务器的账号
		     在主服务器上添加账号
                     grant replication slave on *.* to ‘root’@‘从服务器ip’ identified by ‘123456’;	
		     flush privileges;
		     
		     注:另外在《Hight Performance MySql》一书中对用户权限的设置有所不同，作者建议在主机和从机上都配置root账户，并同时赋予REPLICATION SLAVE和REPLICATION CLIENT权限，命令如下：
mysql> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO repl@'192.168.0.%' IDENTIFIED BY 'repl';
作者解释了这样做的好处：一方面使用同一账户对Replication进行监视管理会很方便，不必区分slave,master，另一方面，repl账户在slave和master上的配制是一样的，这样如果我们切换slave和master，账户不需要做任何改动。

		3.从服务器的配置文件修改my.cnf
		     添加
		     log-bin=master-a-bin #日志文件名称
		     binlog-format=ROW	#二进制日志格式 有row、statement、mixed三种类型
		     server-id=2 #要求各个服务器的这个id不一样
		     log-slave-updates=true  #中继日志这些变化是否计入自己的binlog日志中当你的从服务器需要作为另一台服务器的主服务器的时候需要打开
		4.重启主服务器mysql服务 主服务器查看日志状态 show master status;show master logs; 然后在mysqldump备份主服务器的数据库
		5.从服务器mysql服务重启 
		    设置主从服务的日志、偏移量、登陆的信息
		    在从服务器上执行	
		    change master to
		    master_host=‘主服务器ip’,master_user=‘root’,master_password=‘123456’,master_port=‘3306’,master_log_file=‘在主服务器上show master status 第一列File显示的日志文件名’,master_log_pos=‘主服务器上 show master status 显示的第二行Position 上的数字’;		

		    start slave #开启从服务器
		    show slave status\G;查看状态 主要查看slave_io_running和slave_sql_running状态是否都为有yes、日志名字、偏移量位置position、主服务器的账号密码
端口等是否都一致	

	mysql读写分离
	    MYCAT
	    主服务器操作
	      下载并安装安装mycat 依赖jdk的环境
               配置server.xml配置文件 配置数据库信息
	       配置schema.xml 配置datanode/datehost、writehost/readhost
	    启动mycat
	       ./mycat start
                ps -ef | grep mycat 查看端口
		登陆mycat数据库的管理端口 mysql -uroot -p123456 -Pmycat端口
	    自己写程序
	    
	    mysql-proxy、Amoeba	   

	mysql MHA（高可用 master故障自动切换slave为主）


2.mysql常用函数以及表达式：
	show processlist;  显示连接进程
	show status;
	show variables like '%char%';  查看字符集
	
	常用函数
	length
	concat
	substr
	instr
	trim
	upper
	lower
	lpad
	rpad
	distinct 去重
	replace
	
	round
	ceil
	floor
	truncate
	mod

	now
	curdate
	curtime	
	str_to_date
	date_format
	datediff 日期差
	
	version
	database
	user

	if
	case
	
	sum
	avg
	count
	max
	min

	group by 分组查询	

2.1 MongoDB(非关系型数据库中的文档数据库)
	数据库（多个集合） —-> 集合（多个文档） —> 文档
	数据库和集合都不需要手动创建不存在就会手动创建 在第一次插入文档的时候创建
	
	show dbs —->显示当前所有数据库
	
	use + 表名 —->进入到指定数据库
	
	db —> 显示当前数据库
	
	show collections —-> 查看当前数据库集合

	



3.web网站访问慢排查都有哪些问题影响
	客户端
	（1）网络问题
	（2）dns解析问题
	访问其他网页没问题的话 那就是server端出现的问题
	（1）并发多了之后 服务器的出口带宽不够 或者夸运营商导致的带宽缩减
	（2）服务器负载过高 CPU内存消耗过高
	（3）查询数据库读写耗时太长 代码问题
	（4）数据库过于庞大没有进行优化 每次查询耗时长
	解决办法
	（1）出口带宽或者硬件的优化
	（2）mysql语句优化
	（3）数据库主从复制 读写分离
	（4）使用缓存机制把数据缓存到内存非关系型数据库
	（5）CDN
	（6）网站架构优化 服务器集群或者数据库集群

4.ftp的两种模式
	主动/被动

5.named启动过程
	dns服务器进程 当其启动时自动装载/etc/named.conf 文件定义的dns

6.dns解析过程
	nslookup/dig
	本地hosts - 浏览器缓存 - 本地域名服务器缓存 - 运营商缓存 - 根域名服务器

7.一个目录大于100k的文件copy到另一个目录
	ll -h file awk | ‘{print $5}’
	find . -name ‘*.file’ -size +100k -exce cp -r {} \;
	find . -size +200M -exec ls -lh {} \; | awk  '{print $5,$9}'
	
8.两个服务器拷贝文件的几种方法
	scp/ftp/wget/rsync

9.nginx rewrite各种参数理解以及相关内容
	nginx 可以挂在lua脚本

	last: url重写后，马上发起一个新请求 再次进入server 重新匹配location 超过十次就报500 地址栏不变
	break: url重写后，直接使用当前资源 不再执行location里剩下的语句 完成本次请求 地址栏不变
	redirect: 返回临时的重定向 地址栏显示重定向后的url 302 如果有爬虫不会更新url
	permanet: 返回永久重定向 地址看显示重定向后的url	 301 如果有爬虫会更新url
 	
	（1）proxy_set_header Host $host; 代理服务器携带者真是用户的host
	（2）proxy_set_header X-Real-IP $remote_addr; 携带者真实IP
	（3）proxy_set_header X-Forwarded $proxy_add_x_forwarded_for; 携带真实ip 
	（2）和（3）当服务器无法通过$proxy_add_x_forwarded_for获得ip时应该用$remote_addr;获取ip

	nginx负载均衡配置
	upstream name { server 1   weight=1;
				    server2   weight=2;
                           }
	***
	location / {  
       ****
	proxy_pass http://name;
      }

	nginx和apache区别

	nginx更轻量级占用资源内存少 异步非阻塞的 抗并发高 可以作为反向代理服务器 热升级

	apache同步多进程 nginx异步多个连接对应一个进程 apache 更稳定



	nginx功能:
	静态的web服务器
	反向代理
	负载均衡
	虚拟主机	
	请求转发


	nginx 中如果location 是 alias 必须 location 中的根目录 要和 alias 末级的文件夹一致


	location /admin {
          	alias   /home/data/admin;
          	auth_basic "User Authentication";
          	auth_basic_user_file "/etc/nginx/conf.d/nginxuser";
  

	nginx  中如果 location 是 root 必须 location 中的根目录 要包含在 root 目录中最后一级

	location /admin {
         	root    /home/data;
          	auth_basic "User Authentication";
          	auth_basic_user_file "/etc/nginx/conf.d/nginxuser";
  
          	}






10.ansible发送指令慢解决办法
	关掉 配置文件/etc/ansible/ansible.cfg 中验证秘钥的验证 host_key_checking = False
	网络问题
	关闭 gathering facts  总收集数据 只需要在 playbook 文件中加上“gather_facts: no”即可
	SSH pipelining 是一个加速 Ansible 执行速度的简单方法 默认关闭  之所以默认关闭是为了兼容不同的 sudo 配置 建议开启/etc/ansible/ansible.cfg 

11.linux 服务器优化方法有哪些

12.20台服务器并行 echo 123
	python  pexpect模块 / paramiko模块  远程连接主机模块

13.tcp/ip四层模型
	链路层-网络层-传输层-应用层

14.应用层常用协议
	http\https\DNS\SMTP\FTP

15.某台机器上80端口转发到8089端口上的方法
	本机端口转发:iptables -t nat -A PREROUTING -p tcp - -dport 80 -j REDIRECT - -to-ports 8080
	不同机器端口转发:iptables -t nat -A PREROUTING(路由前)  -p tcp -d 172.16.4.247 --dport 728 -j DNAT --to-destination 172.16.4.97:80 (DNAT用于端口转发)
	              iptables -t nat -A POSTROUTING(路由后) -p tcp -s 172.16.4.97/32 -j SNAT --to-source 172.16.4.247 （SNAT用于内网机器的地址转换上网用）

16.linux 防火墙相关设置

17.sed awk find grep常用方法
	egrep：使用扩展正则表达式来构建模式，相当于grep –E
	find . -name ‘*.txt’ -type d -maxdepth 1 -mtime -1 -size +100k -exce cp -r {} /tmp/  找到当前大于100k的一级目录 最新一天修改过的 并copy到tmp目录下
	find . -type f -exec chmod -R 644 {} \;  当前目录下 所有文件授权644
	
	找到log日志文件删除30天以前的 ：find . -type f -name “*.log” -mtime +30 -exec rm -rf {} \;

	grep “([0-9]{1,3}\.){3}[0-9]{1,3}$” file 匹配ip地址

	awk -F ‘:’ ’{print $1，$NF} ‘ file | head -5 打印文件的第一列前五个	
	
	sed ‘$d’ file 删除 file文件的最后一行  
	sed -i ’s/原内容/替换内容/1’ file 替换字符串 s 参数是替换 1是替换第一个行以此类推 替换所有行用g
	

	sort uniq -c 去重并统计次数 sort -nr 倒序并按照大到小排序

	tcpdump嗅探80端口看谁访问最高
		tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F"." '{print $1"."$2"."$3"."$4}' | sort | uniq -c | sort -nr |head -5&nbsp;
shell
	
		

18.gitlab的安装配置以及备份还原

19.mysql、redis、php等编译安装
	musql初始设置 /etc/my.cnf 开启二进制日志 log-bin



20.http协议 tcp/ip协议
	tcp是一种面向连接的、可靠的传输层协议 tcp传输有三次握手 为应用层提供服务 点对点传输
	ip是网络互连的一种通信协议属于网络层 
	http 是一种超文本传输的应用层协议 基于tcp/ip协议（无状态协议没有记忆能力、无连接的每次只处理一个请求）有请求行、请求头和响构成



21.浏览器访问一个server的过程 一个完整的http请求过程
	浏览器输入域名 首先对域名进行解析 
	根据ip找到对应的服务器 发起tcp三次握手连接
	建立tcp连接之后发起http请求
	服务器响应http请求 返回给浏览器 浏览器解析呈献给用户
	


	

22.shell python
	rpm -qa | grep 查询你安装过的软件包
	rpm -ivh   安装rpm包 --force --nodeps是表示不检查依赖强制安装
	新建20个用户的sh脚本
	seq -f"%02g" 1 20 —> 产生1-20中间的整数不足用0补位
	for i in `seq -f"%02g" 1 20`;do
	useradd user$i
	echo "user$i-`echo $RANDOM|md5sum|cut -c 1-5`"|passwd –stdinuser$i >/dev/null 2>&1
	done

	软连接相当于快捷方式 硬链接相当于复制了一份占空间
	df -h 查看文件系统空间使用情况 df -i 查看inode节点数占用情况
	正则表达式
 	   匹配电话号码 result = re.match(r”1[3,5,6,7,8]\d{9}”,tel)




23.zabbix相关只是点zabbix_proxy
	
	zbbbix安装步骤:
		https://www.zabbix.com/cn/
		

	zabbix客户端安装 zabbix-agent zabbix-sender
	编辑/etc/zabbix/zabbix_agentd.conf的配置文件
	修改Server服务端的 IP地址
	修改主动模式下ServerActive服务端的IP地址
	修改Hostname 这个对应的是zabbix-server端web界面创建host时的主机名保持一致
	然后启动zabbix-agent.service

	手动添加:
		server端添加host configuration - Hosts - Create host

		添加完主机 - items代表要监控的项目 items - create item

		自定义监控内容 自定义key 编辑zabbix_agentd.conf下面一个配置文件内容监控内存使用：UserParameter=memory.used,/usr/bin/free -mh |/usr/bin/awk ‘/^Mem/{print $3}’ 
		重启agent服务

		server端命令行获取agent数据 zabbix_get 命令 先yum -y install zabbix_get 命令 再用zabbix_get -s agentip地址 -p agent端口号 -k “自定义文件里面的名称（memory.user）”
		检查没问题之后 server端web页面添加自定义的item即可（数据刷新有点延迟）
		
	添加监控的模板
		点开主机名 - 模板 - 添加 - 更新  —->自动添加模板的监控项

	自动发现策略:


		server端 configuration - create discover

		配置自动发现规则 名称 - IP地址范围 - 更新时间

		自动发现并添加主机清单 —->用到模板


	zabbix-proxy(分布式)

		和server端不是一个机器
		下载安装zabbix proxy
		yum install -y zabbix-proxy zabbix-proxy-mysql zabbix-agent
		创建zabbix_proxy数据库
		解压zabbix软件包 在解压完的目录里有个database导入两个sql文件
		mysql -uzabbix -p123456 zabbix_proxy < database/mysql/schema.sql
		mysql -uzabbix -p123456 zabbix_proxy < database/mysql/images.sql
				
		安装完zabbix_proxy 会在/usr/local/zabbix/etc/下产生一个zabbix_proxy.conf文件
		配置server端ip hostname 本机主机ip 以及数据库名的账号密码、发送提交数据给服务端的时间等设置

		设置好之后再服务端的web界面添加zabbix_proxy - create proxy - 添加代理服务器ip - 主动模式 - 添加
		添加好代理服务器之后 选择添加主机 如上面 手动添加过程 注意添加时选择是有代理服务器检测而不是server端监控
		添加好的主机也要选择监控项添加一个模板 如自动发现的模板
		客户端的/us/local/zabbix/etc/zabbix_agentd.conf 里面把指向server端的ip改成指向proxy端的ip地址才能获取到数据
		
		



24.gitlab-ci
	持续集成: 持续集成是一天多次将代码合并到主干 通过自动构建的方式验证每次提交 尽早发现问题
	持续集成的价值: 保持随时部署 简化发布流程 尽早发现问题

		
25.CMDB
    配置管理数据库




26.rsync

	






27.lvs(linux虚拟服务器 相当于调度器)	
	集群:多台主机联合起来对外提供一个服务单一系统
	LB:负载均衡
	HA:高可用（）
	HPC:高性能
	
	keepalived 解决lvs单点故障问题
    分布式存储:云盘 （把一个大文件拆分若干小块 每个机器上存储一部分数据 不同机器上会有相同块数据存储）

28.ansible（性能200-300台机器）
	ansible-doc + 模块名字 查看说明
	ansible all -m setup -a ‘filter=“ansible_fqdn”’(setup 系统自带变量) -m 指定模块 -a 执行的命令
	playbook（.yml文件）
	格式	
	— - -
	- hosts: all
	  remote_user: root (以什么身份访问其他服务器)

          vars_files:  —->定义变量
	    - vars.yml	—->引用vars.yml这个文件中的变量 下面的tasks里可以调用	
	  tasks:
	   - name: 自定义功能名字表示这个是做什么的
	     file(指定要用到模块): name=/data/{{ ansible_fqdn}}.log state=touch mode=600    —->引用变量用{{}} state 指定操作类型
		
           - name: install package
	     yum: name=httpd state=present（默认为present）  —->指定state=present为安装 yum 中的state包括（installed=present、absent=removed、latest=最新安装包）
		

	运行 playbook
	    ansible-playbook -C + *.yml （-C检查语法）不加C就直接运行 -e 添加指定变量
	

	template
	    文件名以.j2结尾的 用的是jinja2语言
	    复制模板拷贝文件
	- - - 
	- hosts: all
	  remote_user: root
          
          tasks:
	   - name: install package
   	     yum: name=nginx
	   - name: copy template for centos7
	     template: src=nginxconf7.j2 dest=/etc/nginx/nginx.conf/ backup=yes (如果文件有改动就把dest这个目录下原有的那个文件备份)
	     when: ansible_distribution_major_version==‘7’
	     notify: restart service 
	   - name: copy template for centos6
	     template: src=nginxconf6.j2 dest=/etc/nginx/nginx.conf/ backup=yes 
	     when: ansible_distribution_major_version==‘6’
	     notify: restart service 

	   - name: start service
   	     service: name=nginx state=start enabled=yes
	  
	  handlers:
	   - name: restart service
	     service: name=nginx state=restarted

	  notify 和 handlers 是配合使用 tasks里添加的notify触发handler下面的内容
	  when 判断系统版本 ansible_distribution_major_version（内置变量）是 centos7 还是 centos6 拷贝不通的文件



29.tcp/ip 协议
	传输控制协议/互联网协议 
	包括的协议有:tcp、ip、udp、icmp、telnet、ftp、smtp、arp等
	历史悠久前身是ARP网络诞生和unix一样诞生1969年 早于OSI参考模型
	四层:网络访问层 - 网络层 - 传输层 - 应用层
	
	应用层协议有:http、https ftp smtp dns telnet

	下层协议为上层协议提供服务
	
	tcp               udp 
	可靠	            不可靠
	面向连接           非面向不连接
	数据打包/成段/排序   传输性能高
	错误检查		 无数据恢复
	确认机制
	数据恢复、重传
	

	tcp报头：
		第一层 0-15位:源端口 | 16-31:目的端口
		第二层	序号 （自己发出去的序号）
		第三层 确认号 （对方发过来的序号）
		第四层 数据偏移（数据包头部长度 不确定） | 保留位 | URG(紧急指针位) ACK(确认) PSH(判断数据是否保留在缓存中) RST(重置位) SYN(建立连接使用 SYN=1 ACK=0 同步序号) FIN(结束)（6个标记位）| 窗口(数据的大小)
		第五层	校验位 | 紧急指针
		第六层	可变长度
		
	UDP报头:
		第一层 源端口 目的端口
		第二层 长度	校验
		第三层 数据
	
	ARP先广播拿到mac地址再进行tcp三次握手
	tcp三次握手:
		客户端主动连服务器
		第一步:客户端发送一个SYN位=1和ACK=0 的建立连接的请求 （客户端:close状态 - send状态）
		第二步:服务端回一个SYN位=1和一个ACK位=1 确认收到请求	 （服务端:close状态 - listen状态  服务端:listen - received 状态）
		第三步:客户端回一个ACK位=1的确认 并建立连接（三次握手代表双向确认可靠）（客户端:send - established状态 服务端:received - established状态）


	tcp四次挥手:
		客户端和服务端都有可能发起断开请求
		第一步:客户端发起FIN位=1的包断开请求 (客:establised状态 - fin-wait1状态)
		第二步:服务端回一个ACK位=1的包意思为收到了这个请求（服:establised状态 - close-wait状态 ）
		第三步:服务端再回一个FIN位=1包和ACK位=1的包意思也同意断开 （客:fin-wait1 - fin-wait2状态 服:close-wait - last-ack状态）
		第四步:客户端最后确认断开回一个ACK包 并断开连接 （客:fin-wait2 - time-wait状态 服:last-ack - closed状态 客:time-wait - closed状态）
		
	
	知道ip通过ARP获得mac地址 再进行三次握手

	ARP

	IP
        数据包头部信息: 以太网帧头部信息(最大1500 再大就拆分包) - ip头部 - tcp/udp头部 - 数据(应用层) - 校验位
	  无面向连接 网络层 分层地址 尽力转发 无数据修复
        IP报文头部:
		第一层 版本号(IPV4) | 长度 | 区分服务 | 总长度
		第二层 标识(切分包的标识) |  标志  | 偏移量		
		第三层 生存时间(TTL time to live 经过路由器的数量) | 协议(上层协议类型) | 校验
		第四层 源地址
		第五层	目的地址
		第六层 可选长度
		第七层 数据		
		
	   IP地址：
	    	两部分组成:主机位 + 网络位
		ip地址最多32位
		每个网段的最多可用ip数=2^(n-2) n为32-此网段掩码
		A类:0-127.0.0.0(前8位是网络位) B类:128-191.0.0.0(前16位是网络位) C类:192-223.0.0.0(前24位是网络位) D类:224-239.0.0.0
		私有地址:
		10.0.0.0-10.255.255.255
		172.16.0.0-172.31.255.255
		192.168.0.0-192.168.255.255
		

	
	ICMP


30.python 理解__str__ and  __repr__
	
	两者都是用来实现类的订制

	__repr__ 在使用内建函数 repr()进自动调用

	__str__ 在使用print()进自动调用
	
	好的习惯把这两个定制方法进行重写,从而在输出显示时更方便
	
	例如:
		class Test(object):
    			def __init__(self,value):
        		self.value = value
		t = Test(’name’)
		print(t)
		得到的结果是 :<__main__.Test object at 0x108eb7e10> 显示内存地址
		
		class Test(object):
    			def __init__(self,value):
        		self.value = value
        
    			def __str__(self):

        		    return 'test - <%s>' % self.value

    			def __repr__(self):
			
        		    return 'test2 - <%s>' % self.value
		
		得到的结果: test - <name>
		
		自定义类的显示结果	
	
	理解lamada函数和yield
	
		lamada匿名函数:
			定义了一个表达式 简化了函数定义的书写使得代码更加简洁
			举一个简单的例子：
			def f(x):
  			    return x**2

			Python中使用lambda的话，写成这样
			g = lambda x : x**2
		
		例:
		def testFun():
    		    temp = [lambda x:i*x for i in range(4)]              def testFun():
									     temp = []
    		    return temp                                   ————>      for i in range(4)
								                 temp.append(lamdba x:i*x)
	   	for i in testFun():                            		     return temp
									直接调用函数:print(testFun()) 返回的是一个lambda函数对象
									<function testFun.<locals>.<listcomp>.<lambda> at 0x10a011950>
									将函数赋值 r = testFun() 再重新对变量赋值 才是lambda返回的值 print(r(2))
		    print(i(2))    
		
		输出结果:
		>>>6 6 6 6

		说明:使用lambda的时候，如果不实时指定参数就会用到最后一个 所以每次循环只输出for循环中的最后一位即每次输出2*3

		函数中嵌套lamdba的转换:
		def FunA(x):
		    def FunB(y):
		        for i in range(4):
			    pass
			return i*y
		    return FunB


		上述例子如果要输出0，2，4，6
		改成
		def testFun():
		    temp=[lambda x,i=i:i*x for i in range(4)]  ——->每次循环调用lambda对i重新赋值 否则只会调用最后一个
		    return temp

		for i in testFun():
		    print(i(2))
		输出结果:
		>>>0 2 4 6


		配合map()函数使用
		遍历序列，对序列中每个元素进行操作，最终获取新的序列。
		li = [11, 22, 33]
		sl = [1, 2, 3]
		new_list = map(lambda a, b: a + b, li, sl)
		print(list(new_list))
		结果输出为：
		>>>[12,24,36]

		配合reduce()函数使用
		对于序列内所有元素进行累计操作
		from functools import reduce
		li = [11,22,33]
		result = reduce(lambda a,b:a+b,li)
		# reduce的第一个参数，函数必须要有两个参数
		# reduce的第二个参数，要循环的序列
		# reduce的第三个参数，初始值
		print(result)
		输出结果：
		>>>66

		配合filter()函数使用
		对于序列中的元素进行筛选，最终获取符合条件的序列
		li = [11,22,33]
		new_list = filter(lambda a:a>22,li)
		print(list(new_list))
		#filter第一个参数为空，将获取原来序列
		输出结果：
		>>>[33]

		
		yield 是一个生成器（调用 next 方法才会返回值）
		例子:
		def foo():
    		    print("starting...")
                 while True:
                    res = yield 4
                    print("res:",res)

            g = foo()
            print(next(g))
            print("*"*20)
	      print(next(g))

		输出结果
		starting...
		4
		********************
		res: None
		4

		
		分析:
		1.当第一次调用程序的时候并没有返回值 所以foo函数并不会真的执行，而是先得到一个生成器g(相当于一个对象)
		2.直到调用next方法，foo函数正式开始执行，先执行foo函数中的print方法，然后进入while循环
		3.程序遇到yield关键字，然后把yield想想成return,return了一个4之后，程序停止，并没有执行赋值给res操作，此时next(g)语句执行完成，所以输出的前两行（第一个是while上面的print的结果,第二个是return出的结果）是执行第一个print(next(g))的结果，
		4.程序执行print("*"*20)，输出20个*
		5.又开始执行下面的print(next(g)),这个时候和上面那个差不多，不过不同的是，这个时候是从刚才那个next程序停止的地方开始执行的，也就是要执行res的赋值操作，这时候要注意，这个时候赋值操作的右边是没有值的（因为刚才那个是return出去了，并没有给赋值操作的左边传参数），所以这个时候res赋值是None,所以接着下面的输出就是res:None,
		6.程序会继续在while里执行，又一次碰到yield,这个时候同样return 出4，然后程序停止，print函数输出的4就是这次return出的4.
		
		理解:
		到这里你可能就明白yield和return的关系和区别了，带yield的函数是一个生成器，而不是一个函数了，这个生成器有一个函数就是next函数，next就相当于“下一步”生成哪个数，这一次的next开始的地方是接着上一次的next停止的地方执行的，所以调用next的时候，生成器并不会从foo函数的开始执行，只是接着上一步停止的地方开始，然后遇到yield后，return出要生成的数，此步就结束。

		

	python 多线程 多进程 （多线程共享全局变量 进程之间相互独立）
	    现有进程 才有线程  线程依赖于进程
	    并行:真的多任务
	    并发:加的多任务一起
	    多线程:资源少，操作系统调度的单位 真正执行的是线程            ——> 进程就是工厂中的一条流水线 线程就是流水线上的工人
	    多进程:消耗资源多 资源浪费 资源分配的单位
 
	    线程池 - 重复利用  线程中异常不打印出来
	    线程池中创建队列队列 用的是 multiprocessing.Manager()下面的Queue 而不是 queue中的Queue 
	    queue = multiprocessing.Manager().Queue() 




	迭代器:
	    迭代器占用的空间资源小 只是返回一个对象 实现的方法 而不存储数据
	    不仅是for循环用到的迭代器 数据类型转换的如 list、tuple的转换也用到了迭代器
	    
	    如果这个对象可迭代 首先必须这个类里面要有__iter__方法  说明这个类可迭代
	    并且这个方法必须返回一个具有__next__和__iter__方法的引用(即就是返回self 返回自己 然后自己再有一个 __next__发方法) 就说这个类是个迭代器
	    for 循环其实就是调用 具有__next__和__iter__方法的这个类 里面的__next__(self)方法返回的东西

	    总结:如果一个对象是个迭代器 那他肯定是可迭代的  如果一个可迭代的对象 不一定是一个迭代器
		
	    




	CDN入门:
	    1.什么是cdn
		 内容分发网络 - 一套系统
	         一种透过互联网相互连接的计算机网络系统 达到的目标 快/稳

	    2.为什么要用cdn
	        多个基础运营商
		提高用户访问速度
		多节点冗余 提高可靠性

	    3.主要类型
		静态加速(txt、jpg、MP4、m3u8) 源站 - 二级节点
		动态CDN加速(反向代理)
		直播CDN加速(rtmp、httpflv(拉流)) 直播 - rtmp 推流

	    4.调度方法
		传统dns（CNAME）
		HttpDNS(api接口)



 	    5.计费方式
		按流量或带宽
		按日峰值月平均
		按95峰值带宽计费

	    6.常见故障
		调度错误
		请求劫持
		节点故障
		回源失败(源站故障)





















	生成器:
	    生成器是一种特殊的迭代器 不是类是个函数 没有next和iter方法
	    创建生成器的第一种方法: 
	    列表推导式的中括号变成 小括号
	    num = [x for x in range(10)]  ———> 返回的是一个列表

	    num = (x for x in range(10))  ———> 返回的是一个生成器	    
	
	    创建生成器的第二种方法:
	    函数中有yield 这个函数就变成了 生成器   可以用next方法调用对象返回值 还可以用 对象.send()的方法启动生成器 并且可以传参数 参数传给yield返回的值ß
	    函数碰到yield就暂停并把yield后面的值返回 下次再调用的时候接着上次暂停的地方继续执行 而不是从头开始
	    

	yield实现多任务 并行交替实现:
	import time

	def task1():
    	    while True:
                print('---1---')
                time.sleep(0.1)
                yield

	def task2():
            while True:
                print('---2---')
                time.sleep(0.1)
                yield

	def main():
    	    t1 = task1()
            t2 = task2()
    	    while True:
                next(t1)
                next(t2)
        if __name__== "__main__":
    	    main()
	    
	进程、线程、协程 对比:
	    1）进程是资源分配的单位
	    2）线程是操作系统调度的单位
	    3）进程切换需要的资源很大 效率低
	    4）线程切换需要的资源一般 效率一般
	    5）协程切换任务需要的资源很小 效率高 (网络io多的一般用这个)
	    6）多进程、多线程根据cpu的核数不一样可能是并行的 但是协程在一个线程中 是并发的（并行是多个任务同时处理一个任务一个cpu 并发是多个程序同时运行在一个cpu上进行切换）
	    




高可用性

jumpserver

	




















