

1) 整理内容

、、、
1. mysql主从备份延迟以及实际相关问题
	原理	
	异步
	主库对写的的操作写进binlog
	并产生一个线程 用户给从库I/O线程读取binlog日志
	从库请求主库的binlog日志 并将日志写到自己的relayl og日志中
	从库线程会读取relay log日志的内容解析成具体sql语句并执行
	主库是并发的 从库的单线程却不是
	
	可能延迟的原因
	主库负载过高 从库负载过高 网络延迟 机器性能低 mysql配置问题
	
	主从同步延迟的产生
	主库并发较高是 产生的数量超过从库一个sql线程的承受范围
	
	解决延迟的方法
	简单的减少slave同步延时的方案就是在架构上做优化，尽量让主库的DDL快速执行。	还有就是主库是写，对数据安全性较高，比如 sync_binlog=1，	innodb_flush_log_at_trx_commit = 1 之类的设置，而slave则不需要这么高的	数据安全，完全可以讲sync_binlog设置为0或者关闭binlog，innodb_flushlog也 	可以设置为0来提高sql的执行效率。另外就是使用比主库更好的硬件设备作为slave。
	
	
	mysql备份	
	   备份sql文件 mysqldump -uroot -p123456 -B 数据库名 表名> test.sql  还原 mysql -uroot -p123456 数据库名 < test.sql
           test文本备份 select * from student into outfile '/var/lib/mysql-files/tt.txt';  还原 load data infile '/var/lib/mysql-files/tt.txt' into table student;
	mysql设置客户端访问权限
	    grant all privileges on *.* to ‘root’@‘%’ identified by ‘123456’ with grant option;
	    flush privileges;

	mysql修改登录密码编辑/etc/my.cnf
		[mysqld]
		 skip-grant-tables —->跳过权限验证直接登录
		修改root密码 先刷新权限相关的表 flush privileges;
		set password for root@localhost = password(‘123456’);或者
		use mysql; update user set password=PASSWORD(‘123456’)WHERE user=’root’; 
		再刷新 flush privileges;
		最后在注释掉
		[mysqld]
		#skip-grant-tables
		重启mysql服务

	mysql主从复制读写分离分库分表
		主库从库有相同的数据库和表
		1.修改主服务器的同步日志my.cnf配置文件
		     添加
		     log-bin=master-a-bin #日志文件名称
		     binlog-format=ROW	#二进制日志格式 有row、statement、mixed三种类型
		     server-id=1 #要求各个服务器的这个id不一样
		     binlog-do-db=需要同步的数据库名称
		2.设置从服务器登陆主服务器的账号
		     在主服务器上添加账号
                     grant replication slave on *.* to ‘root’@‘从服务器ip’ identified by ‘123456’;	
		     flush privileges;
		     
		     注:另外在《Hight Performance MySql》一书中对用户权限的设置有所不同，作者建议在主机和从机上都配置root账户，并同时赋予REPLICATION SLAVE和REPLICATION CLIENT权限，命令如下：
mysql> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO repl@'192.168.0.%' IDENTIFIED BY 'repl';
作者解释了这样做的好处：一方面使用同一账户对Replication进行监视管理会很方便，不必区分slave,master，另一方面，repl账户在slave和master上的配制是一样的，这样如果我们切换slave和master，账户不需要做任何改动。

		3.从服务器的配置文件修改my.cnf
		     添加
		     log-bin=master-a-bin #日志文件名称
		     binlog-format=ROW	#二进制日志格式 有row、statement、mixed三种类型
		     server-id=2 #要求各个服务器的这个id不一样
		     log-slave-updates=true  #中继日志这些变化是否计入自己的binlog日志中当你的从服务器需要作为另一台服务器的主服务器的时候需要打开
		4.重启主服务器mysql服务 主服务器查看日志状态 show master status;show master logs; 然后在mysqldump备份主服务器的数据库
		5.从服务器mysql服务重启 
		    设置主从服务的日志、偏移量、登陆的信息
		    在从服务器上执行	
		    change master to
		    master_host=‘主服务器ip’,master_user=‘root’,master_password=‘123456’,master_port=‘3306’,master_log_file=‘在主服务器上show master status 第一列File显示的日志文件名’,master_log_pos=‘主服务器上 show master status 显示的第二行Position 上的数字’;		

		    start slave #开启从服务器
		    show slave status\G;查看状态 主要查看slave_io_running和slave_sql_running状态是否都为有yes、日志名字、偏移量位置position、主服务器的账号密码端口等是否都一致
	

	mysql读写分离
	    自己写程序
	    mysql-proxy、Amoeba	   




2.mysql常用函数以及表达式：
	show processlist;  显示连接进程
	show status;
	show variables like '%char%';  查看字符集
	
	常用函数
	length
	concat
	substr
	instr
	trim
	upper
	lower
	lpad
	rpad
	distinct 去重
	replace
	
	round
	ceil
	floor
	truncate
	mod

	now
	curdate
	curtime	
	str_to_date
	date_format
	datediff 日期差
	
	version
	database
	user

	if
	case
	
	sum
	avg
	count
	max
	min

	group by 分组查询	

2.1 MongoDB(非关系型数据库中的文档数据库)
	数据库（多个集合） —-> 集合（多个文档） —> 文档
	数据库和集合都不需要手动创建不存在就会手动创建 在第一次插入文档的时候创建
	
	show dbs —->显示当前所有数据库
	
	use + 表名 —->进入到指定数据库
	
	db —> 显示当前数据库
	
	show collections —-> 查看当前数据库集合

	



3.web网站访问慢排查都有哪些问题影响
	客户端
	（1）网络问题
	（2）dns解析问题
	访问其他网页没问题的话 那就是server端出现的问题
	（1）并发多了之后 服务器的出口带宽不够 或者夸运营商导致的带宽缩减
	（2）服务器负载过高 CPU内存消耗过高
	（3）查询数据库读写耗时太长 代码问题
	（4）数据库过于庞大没有进行优化 每次查询耗时长
	解决办法
	（1）出口带宽或者硬件的优化
	（2）mysql语句优化
	（3）数据库主从复制 读写分离
	（4）使用缓存机制把数据缓存到内存非关系型数据库
	（5）CDN
	（6）网站架构优化 服务器集群或者数据库集群

4.ftp的两种模式
	主动/被动

5.named启动过程
	dns服务器进程 当其启动时自动装载/etc/named.conf 文件定义的dns

6.dns解析过程
	nslookup/dig
	本地hosts - 浏览器缓存 - 本地域名服务器缓存 - 运营商缓存 - 根域名服务器

7.一个目录大于100k的文件copy到另一个目录
	ll -h file awk | ‘{print $5}’
	find . -name ‘*.file’ -size +100k -exce cp -r {} \;
	find . -size +200M -exec ls -lh {} \; | awk  '{print $5,$9}'
	
8.两个服务器拷贝文件的几种方法
	scp/ftp/wget

9.nginx rewrite各种参数理解以及相关内容
	nginx 可以挂在lua脚本

	last: url重写后，马上发起一个新请求 再次进入server 重新匹配location 超过十次就报500 地址栏不变
	break: url重写后，直接使用当前资源 不再执行location里剩下的语句 完成本次请求 地址栏不变
	redirect: 返回临时的重定向 地址栏显示重定向后的url 302 如果有爬虫不会更新url
	permanet: 返回永久重定向 地址看显示重定向后的url	 301 如果有爬虫会更新url
 	
	（1）proxy_set_header Host $host; 代理服务器携带者真是用户的host
	（2）proxy_set_header X-Real-IP $remote_addr; 携带者真实IP
	（3）proxy_set_header X-Forwarded $proxy_add_x_forwarded_for; 携带真实ip 
	（2）和（3）当服务器无法通过$proxy_add_x_forwarded_for获得ip时应该用$remote_addr;获取ip

	nginx负载均衡配置
	upstream name { server 1   weight=1;
				    server2   weight=2;
                           }
	***
	location / {  
       ****
	proxy_pass http://name;
      }

	nginx和apache区别

	nginx更轻量级占用资源内存少 异步非阻塞的 抗并发高 可以作为反向代理服务器 热升级

	apache同步多进程 nginx异步多个连接对应一个进程 apache 更稳定



	nginx功能:
	静态的web服务器
	反向代理
	负载均衡
	虚拟主机	
	请求转发


	nginx 中如果location 是 alias 必须 location 中的根目录 要和 alias 末级的文件夹一致


	location /admin {
          	alias   /home/data/admin;
          	auth_basic "User Authentication";
          	auth_basic_user_file "/etc/nginx/conf.d/nginxuser";
  

	nginx  中如果 location 是 root 必须 location 中的根目录 要包含在 root 目录中最后一级

	location /admin {
         	root    /home/data;
          	auth_basic "User Authentication";
          	auth_basic_user_file "/etc/nginx/conf.d/nginxuser";
  
          	}






10.ansible发送指令慢解决办法
	关掉 配置文件/etc/ansible/ansible.cfg 中验证秘钥的验证 host_key_checking = False
	网络问题
	关闭 gathering facts  总收集数据 只需要在 playbook 文件中加上“gather_facts: no”即可
	SSH pipelining 是一个加速 Ansible 执行速度的简单方法 默认关闭  之所以默认关闭是为了兼容不同的 sudo 配置 建议开启/etc/ansible/ansible.cfg 

11.linux 服务器优化方法有哪些

12.20台服务器并行 echo 123
	python  pexpect模块 / paramiko模块  远程连接主机模块

13.tcp/ip四层模型
	链路层-网络层-传输层-应用层

14.应用层常用协议
	http\https\DNS\SMTP\FTP

15.某台机器上80端口转发到8089端口上的方法
	本机端口转发:iptables -t nat -A PREROUTING -p tcp - -dport 80 -j REDIRECT - -to-ports 8080
	不同机器端口转发:iptables -t nat -A PREROUTING(路由前)  -p tcp -d 172.16.4.247 --dport 728 -j DNAT --to-destination 172.16.4.97:80 (DNAT用于端口转发)
	              iptables -t nat -A POSTROUTING(路由后) -p tcp -s 172.16.4.97/32 -j SNAT --to-source 172.16.4.247 （SNAT用于内网机器的地址转换上网用）

16.linux 防火墙相关设置

17.sed awk find grep常用方法
	egrep：使用扩展正则表达式来构建模式，相当于grep –E
	find . -name ‘*.txt’ -type d -maxdepth 1 -mtime -1 -size +100k -exce cp -r {} /tmp/  找到当前大于100k的一级目录 最新一天修改过的 并copy到tmp目录下
	find . -type f -exec chmod -R 644 {} \;  当前目录下 所有文件授权644
	
	找到log日志文件删除30天以前的 ：find . -type f -name “*.log” -mtime +30 -exec rm -rf {} \;

	grep “([0-9]{1,3}\.){3}[0-9]{1,3}$” file 匹配ip地址

	awk -F ‘:’ ’{print $1，$NF} ‘ file | head -5 打印文件的第一列前五个	
	
	sed ‘$d’ file 删除 file文件的最后一行  
	sed -i ’s/原内容/替换内容/1’ file 替换字符串 s 参数是替换 1是替换第一个行以此类推 替换所有行用g
	

	sort uniq -c 去重并统计次数 sort -nr 倒序并按照大到小排序

	tcpdump嗅探80端口看谁访问最高
		tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F"." '{print $1"."$2"."$3"."$4}' | sort | uniq -c | sort -nr |head -5&nbsp;
shell
	
		

18.gitlab的安装配置以及备份还原

19.mysql、redis、php等编译安装
	musql初始设置 /etc/my.cnf 开启二进制日志 log-bin



20.http协议 tcp/ip协议
	tcp是一种面向连接的、可靠的传输层协议 tcp传输有三次握手 为应用层提供服务 点对点传输
	ip是网络互连的一种通信协议属于网络层 
	http 是一种超文本传输的应用层协议 基于tcp/ip协议（无状态协议没有记忆能力、无连接的每次只处理一个请求）有请求行、请求头和响构成



21.浏览器访问一个server的过程 一个完整的http请求过程
	浏览器输入域名 首先对域名进行解析 
	根据ip找到对应的服务器 发起tcp三次握手连接
	建立tcp连接之后发起http请求
	服务器响应http请求 返回给浏览器 浏览器解析呈献给用户
	


	

22.shell python
	rpm -qa | grep 查询你安装过的软件包
	rpm -ivh   安装rpm包 --force --nodeps是表示不检查依赖强制安装
	新建20个用户的sh脚本
	seq -f"%02g" 1 20 —> 产生1-20中间的整数不足用0补位
	for i in `seq -f"%02g" 1 20`;do
	useradd user$i
	echo "user$i-`echo $RANDOM|md5sum|cut -c 1-5`"|passwd –stdinuser$i >/dev/null 2>&1
	done

	软连接相当于快捷方式 硬链接相当于复制了一份占空间
	df -h 查看文件系统空间使用情况 df -i 查看inode节点数占用情况
	正则表达式
 	   匹配电话号码 result = re.match(r”1[3,5,6,7,8]\d{9}”,tel)




23.zabbix相关只是点zabbix_proxy
	
	zbbbix安装步骤:
		https://www.zabbix.com/cn/
		

	zabbix客户端安装 zabbix-agent zabbix-sender
	编辑/etc/zabbix/zabbix_agentd.conf的配置文件
	修改Server服务端的 IP地址
	修改主动模式下ServerActive服务端的IP地址
	修改Hostname 这个对应的是zabbix-server端web界面创建host时的主机名保持一致
	然后启动zabbix-agent.service

	手动添加:
		server端添加host configuration - Hosts - Create host

		添加完主机 - items代表要监控的项目 items - create item

		自定义监控内容 自定义key 编辑zabbix_agentd.conf下面一个配置文件内容监控内存使用：UserParameter=memory.used,/usr/bin/free -mh |/usr/bin/awk ‘/^Mem/{print $3}’ 
		重启agent服务

		server端命令行获取agent数据 zabbix_get 命令 先yum -y install zabbix_get 命令 再用zabbix_get -s agentip地址 -p agent端口号 -k “自定义文件里面的名称（memory.user）”
		检查没问题之后 server端web页面添加自定义的item即可（数据刷新有点延迟）
		
	添加监控的模板
		点开主机名 - 模板 - 添加 - 更新  —->自动添加模板的监控项

	自动发现策略:


		server端 configuration - create discover

		配置自动发现规则 名称 - IP地址范围 - 更新时间

		自动发现并添加主机清单 —->用到模板


	zabbix-proxy(分布式)

		和server端不是一个机器
		下载安装zabbix proxy
		yum install -y zabbix-proxy zabbix-proxy-mysql zabbix-agent
		创建zabbix_proxy数据库
		解压zabbix软件包 在解压完的目录里有个database导入两个sql文件
		mysql -uzabbix -p123456 zabbix_proxy < database/mysql/schema.sql
		mysql -uzabbix -p123456 zabbix_proxy < database/mysql/images.sql
				
		安装完zabbix_proxy 会在/usr/local/zabbix/etc/下产生一个zabbix_proxy.conf文件
		配置server端ip hostname 本机主机ip 以及数据库名的账号密码、发送提交数据给服务端的时间等设置

		设置好之后再服务端的web界面添加zabbix_proxy - create proxy - 添加代理服务器ip - 主动模式 - 添加
		添加好代理服务器之后 选择添加主机 如上面 手动添加过程 注意添加时选择是有代理服务器检测而不是server端监控
		添加好的主机也要选择监控项添加一个模板 如自动发现的模板
		客户端的/us/local/zabbix/etc/zabbix_agentd.conf 里面把指向server端的ip改成指向proxy端的ip地址才能获取到数据
		
		



24.gitlab-ci
	持续集成: 持续集成是一天多次将代码合并到主干 通过自动构建的方式验证每次提交 尽早发现问题
	持续集成的价值: 保持随时部署 简化发布流程 尽早发现问题

		






高可用性

jumpserver






















