

1) 整理内容

、、、
1. mysql主从备份延迟以及实际相关问题
	原理	
	异步
	主库对写的的操作写进binlog
	并产生一个线程 用户给从库I/O线程读取binlog日志
	从库请求主库的binlog日志 并将日志写到自己的relayl og日志中
	从库线程会读取relay log日志的内容解析成具体sql语句并执行
	主库是并发的 从库的单线程却不是
	
	可能延迟的原因
	主库负载过高 从库负载过高 网络延迟 机器性能低 mysql配置问题
	
	主从同步延迟的产生
	主库并发较高是 产生的数量超过从库一个sql线程的承受范围
	
	解决延迟的方法
	简单的减少slave同步延时的方案就是在架构上做优化，尽量让主库的DDL快速执行。	还有就是主库是写，对数据安全性较高，比如 sync_binlog=1，	innodb_flush_log_at_trx_commit = 1 之类的设置，而slave则不需要这么高的	数据安全，完全可以讲sync_binlog设置为0或者关闭binlog，innodb_flushlog也 	可以设置为0来提高sql的执行效率。另外就是使用比主库更好的硬件设备作为slave。
	

	
	

2.mysql查看连接进程
	show processlist;
	show status;

3.web网站访问慢排查都有哪些问题影响
	客户端
	（1）网络问题
	（2）dns解析问题
	访问其他网页没问题的话 那就是server端出现的问题
	（1）并发多了之后 服务器的出口带宽不够 或者夸运营商导致的带宽缩减
	（2）服务器负载过高 CPU内存消耗过高
	（3）查询数据库读写耗时太长 代码问题
	（4）数据库过于庞大没有进行优化 每次查询耗时长
	解决办法
	（1）出口带宽或者硬件的优化
	（2）mysql语句优化
	（3）数据库主从复制 读写分离
	（4）使用缓存机制把数据缓存到内存非关系型数据库
	（5）CDN
	（6）网站架构优化 服务器集群或者数据库集群

4.ftp的两种模式
	主动/被动

5.named启动过程
	dns服务器进程 当其启动时自动装载/etc/named.conf 文件定义的dns

6.dns解析过程
	nslookup/dig
	本地hosts - 浏览器缓存 - 系统缓存 -路由器缓存 - 运营商缓存 - 根域名服务器

7.一个目录大于100k的文件copy到另一个目录
	ll -h file awk | ‘{print $5}’
	
8.两个服务器拷贝文件的几种方法
	scp/ftp/wget

9.nginx rewrite各种参数理解以及相关内容
	last: url重写后，马上发起一个新请求 再次进入server 重新匹配location 超过十次就报500 地址栏不变
	break: url重写后，直接使用当前资源 不再执行location里剩下的语句 完成本次请求 地址栏不变
	redirect: 返回临时的重定向 地址栏显示重定向后的url 302 如果有爬虫不会更新url
	permanet: 返回永久重定向 地址看显示重定向后的url	 301 如果有爬虫会更新url
 	
	（1）proxy_set_header Host $host; 代理服务器携带者真是用户的host
	（2）proxy_set_header X-Real-IP $remote_addr; 携带者真实IP
	（3）proxy_set_header X-Forwarded $proxy_add_x_forwarded_for; 携带真实ip 
	（2）和（3）当服务器无法通过$proxy_add_x_forwarded_for获得ip时应该用$remote_addr;获取ip

	nginx负载均衡配置
	upstream name { server 1   weight=1;
				    server2   weight=2;
                           }
	***
	location / {  
       ****
	proxy_pass http://name;
      }

10.ansible发送指令慢解决办法
	关掉 配置文件/etc/ansible/ansible.cfg 中验证秘钥的验证 host_key_checking = False
	网络问题
	关闭 gathering facts  总收集数据 只需要在 playbook 文件中加上“gather_facts: no”即可
	SSH pipelining 是一个加速 Ansible 执行速度的简单方法 默认关闭  之所以默认关闭是为了兼容不同的 sudo 配置 建议开启/etc/ansible/ansible.cfg 

11.linux 服务器优化方法有哪些

12.20台服务器并行 echo 123
	python  pexpect模块 / paramiko模块  远程连接主机模块

13.tcp/ip四层模型
	链路层-网络层-传输层-应用层

14.应用层常用协议
	http\https\DNS\SMTP\FTP

15.某台机器上80端口转发到8089端口上的方法
	本机端口转发:iptables -t nat -A PREROUTING -p tcp - -dport 80 -j REDIRECT - -to-ports 8080
	不同机器端口转发:
16.linux 防火墙相关设置

17.sed awk 常用方法

18.gitlab的安装配置以及备份还原

19.mysql、redis、php等编译安装



20.http协议 tcp/ip协议
	tcp是一种面向连接的、可靠的传输层协议 tcp传输有三次握手 为应用层提供服务 点对点传输
	ip是网络互连的一种通信协议属于网络层 
	http 是一种超文本传输的应用层协议 基于tcp/ip协议（无状态协议没有记忆能力、无连接的每次只处理一个请求）有请求行、请求头和响构成



21.浏览器访问一个server的过程 一个完整的http请求过程
	浏览器输入域名 首先对域名进行解析 
	根据ip找到对应的服务器 发起tcp三次握手连接
	建立tcp连接之后发起http请求
	服务器响应http请求 返回给浏览器 浏览器解析呈献给用户
	


22.Docker-file一些命令 docker-file是干什么的
	
	配置阿里的镜像源
	docker pull下载拉取一个镜像

	docker built -f + 文件目录 -t + 新镜像名字 + ‘.’ Dokerfile 文件所在目录 也可以是绝对路径
	
	docker images查看生成的镜像

	docker run -itd + 镜像id或者名字:加版本

	docker-file是用来构建docker镜像的构建文件 是有一系列命令和参数构成的脚本
	写docker-file —> bulid —> run 三步骤

	docker run -it -p 7777:8080 tomcat 映射容器的端口

	docker history + 镜像id 查看镜像的生成过程
	
	格式：
	FROM 原镜像 Base镜像（scrath）
	MAINTAINER 作者和邮箱的一些信息
	ADD 
	LABEL




	CMD [‘/bin/bash’] (运行镜像的时候 以/bin/bash的环境运行)
	
	基本知识：（1）每条保留字指令都必须为大写字母且后面要至少跟随一个参数
		（2）指令从上到下顺序执行
		（3）每条指令都会创建一个镜像层，并对镜像进行提交

	执行的大致流程：（1） docker从基础镜像运行一个容器
		     （2） 执行每一条指令并对容器进行修改
		     （3） 执行类似docker commit 的命令提交一个新的镜像层     ——>  最终形成一个镜像
		     （4） docker 在基于刚才提交的镜像运行一个新容器
		     （5） 执行dockerfile中的每一条指令到所有都完成




	FROM ：基础经镜像的来源
	

23.shell python




、、、

nginx和apache区别

nginx更轻量级占用资源内存少 异步非阻塞的 抗并发高 可以作为反向代理服务器 热升级

apache同步多进程 nginx异步多个连接对应一个进程 apache 更稳定






nginx功能:
静态的web服务器
反向代理
负载均衡
虚拟主机
请求转发


nginx 中如果location 是 alias 必须 location 中的根目录 要和 alias 末级的文件夹一致


location /admin {
          alias   /home/data/admin;
          auth_basic "User Authentication";
          auth_basic_user_file "/etc/nginx/conf.d/nginxuser";
  

nginx  中如果 location 是 root 必须 location 中的根目录 要包含在 root 目录中最后一级

location /admin {
         root    /home/data;
          auth_basic "User Authentication";
          auth_basic_user_file "/etc/nginx/conf.d/nginxuser";
  
          }





docker
zabbix





